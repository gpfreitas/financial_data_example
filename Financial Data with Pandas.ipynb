{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Tick Data with pandas\n",
    "\n",
    "We will work with data from [QuantQuote](https://quantquote.com/historical-stock-data).\n",
    "\n",
    "- Dimensions: date, time, stock symbol\n",
    "- Metrics: opening, high, low and closing prices, as well as trade volume\n",
    "- Frequency: daily\n",
    "- Dates: 1998 to 2015\n",
    "- Scope: 500 stock symbols that constitute the S&P500 as of Dec 2015.\n",
    "\n",
    "Let's get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def download(url):\n",
    "    local_fname = url.split('/')[-1]\n",
    "    fname, headers = urlretrieve(url, local_fname)\n",
    "    return fname, headers\n",
    "\n",
    "data_url = 'http://quantquote.com/files/quantquote_daily_sp500_83986.zip'\n",
    "metadata_url = 'https://quantquote.com/docs/QuantQuote_Minute.pdf'\n",
    "\n",
    "# Download data\n",
    "data_fname, data_headers = download(data_url)\n",
    "# Extract the data\n",
    "with ZipFile(data_fname) as zf:\n",
    "    zf.extractall()\n",
    "\n",
    "# Download PDF with the metadata\n",
    "metadata_fname, metadata_headers = download(metadata_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each one of the 500 stock symbols, we have a file. Here is a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "data_dir = os.path.join('quantquote_daily_sp500_83986', 'daily')\n",
    "pprint(os.listdir(data_dir)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the downloaded PDF (see `metadata_fname`) we can obtain the field names (and their descriptions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fieldnames = [\n",
    "    'date',\n",
    "    'time',\n",
    "    'open',\n",
    "    'high',\n",
    "    'low',\n",
    "    'close',\n",
    "    'volume' \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the dataset for a single stock symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now easily import the data of a single stock, for example, Apple (AAPL). We will drop the `time` field because it's useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print(plt.style.available)\n",
    "plt.style.use('seaborn-notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def import_data(symbol, fieldnames=fieldnames, set_index=True, add_symbol=False):\n",
    "    data_path = os.path.join('quantquote_daily_sp500_83986',\n",
    "                             'daily',\n",
    "                             'table_' + symbol + '.csv')\n",
    "    data = pd.read_csv(data_path,\n",
    "                       names=fieldnames).drop('time', axis=1)\n",
    "    data['date'] = pd.to_datetime(data.date, format='%Y%m%d')\n",
    "    if set_index:\n",
    "        data.set_index('date', inplace=True)\n",
    "    if add_symbol:\n",
    "        data['symbol'] = symbol\n",
    "    return data\n",
    "\n",
    "aapl = import_data('aapl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(aapl.info())\n",
    "print(aapl.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly look at things like the closing prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aapl.close.plot(title='AAPL closing prices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of plot where you have a lot of data points in the x-axis begs for interactivity: sometimes we want to inspect prices dates where something happened. Bokeh can help greatly here, allowing you to zoom in the dates you are interested in easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bokeh.charts, bokeh.io\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = bokeh.charts.Line(aapl.close.reset_index(), x='date', y='close')\n",
    "p.notebook(True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the relative difference between open and close prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_df = (aapl.close - aapl.open) / aapl.open\n",
    "print(_df.describe())\n",
    "_df.plot(title='AAPL relative difference between close and open prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_df.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a dataset for all stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you should check if the data is \"too big\" just by looking at its size. It's 35M compressed, so we will be fine loading it all in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_data_dir = os.path.join('quantquote_daily_sp500_83986', 'daily')\n",
    "\n",
    "def make_dataset(data_dir=_data_dir):      \n",
    "    data_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "    symbols = [os.path.splitext(f)[0].split('_')[1] for f in data_files]\n",
    "    df_by_symbol = (import_data(s, set_index=False, add_symbol=True)\n",
    "                    for s in symbols)\n",
    "    df = pd.concat(df_by_symbol)\n",
    "    \n",
    "    # Encode categorical variables efficiently\n",
    "    df['symbol'] = df.symbol.astype('category')\n",
    "    # Set an index and assert it is well behaved\n",
    "    df = df.set_index(['symbol', 'date']).sort_index()\n",
    "    assert df.index.is_unique and df.index.is_monotonic\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time df = make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby(level='symbol').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now, for example, plot the closing prices of the top 20 stocks according to some ranking metric (let's say trading volume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top20sym = (\n",
    "    df.groupby(level='symbol')\n",
    "      .sum()\n",
    "      .sort_values(by='volume', ascending=False)\n",
    "      .head(20)\n",
    "      .index\n",
    "      .tolist()\n",
    ")\n",
    "\n",
    "top20sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top20 = df.loc[(top20sym,slice(None)), ['open', 'close']]\n",
    "\n",
    "top20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top20.close.unstack('symbol').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top20.close.unstack('symbol').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to exclude AAPL from the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top20.close.drop('aapl').unstack('symbol').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bokeh plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sbn\n",
    "\n",
    "sbn.heatmap(top20.close.unstack('symbol').corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
